import sys
import io
import datetime
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from reportlab.lib import colors
from reportlab.lib.pagesizes import letter
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from xml.etree import ElementTree as ET

# Pick below for testing
gene_symbol = "NLGN4X"
hgvs_cdna_transcript_id = "NM_001282145:c.302G>A"

#gene_symbol = "EGFR"
#hgvs_cdna_transcript_id = "NM_005228.3:c.2648T>C"

#gene_symbol = "KCNMA1"
#hgvs_cdna_transcript_id = "NM_001014797.2:c.2996A>G"

output_pdf_file_path = fr"C:\Users\anmbh\OneDrive\Documents\PhD_Thesis_Work\Practice Case\{gene_symbol}.pdf"

def capture_output(func):
    def wrapper(*args, **kwargs):
        output_buffer = io.StringIO()
        sys.stdout = output_buffer
        func(*args, **kwargs)
        captured_text = output_buffer.getvalue()
        sys.stdout = sys.__stdout__
        return captured_text
    return wrapper

def split_and_style(line, normal_style):
    parts = line.split(':', 1)
    if len(parts) > 1:
        return Paragraph(f"<b>{parts[0]}:</b> {parts[1].strip()}", normal_style)
    return Paragraph(line, normal_style)

def create_protein_domains_table(domains):
    title = Paragraph("<b>Protein Domains</b>", getSampleStyleSheet()['Heading2'])
    data = [["Source", "Description", "Start", "End"]]
    for domain in domains:
        row = [
            domain.get('Source', 'N/A'),
            domain.get('Description', 'N/A'),
            domain.get('Start', 'N/A'),
            domain.get('End', 'N/A')
        ]
        data.append(row)

    table = Table(data, colWidths=[100, 250, 50, 50])
    table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 12),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black),
    ]))
    return [title, Spacer(1, 12), table]


def create_pdf_from_text(text, output_path):
    styles = getSampleStyleSheet()
    normal_style = styles['Normal']
    bold_style = ParagraphStyle(name='BoldStyle', parent=styles['Normal'], fontName='Helvetica-Bold')
    header_style = ParagraphStyle(name='HeaderStyle', parent=styles['Heading1'], fontSize=14, spaceAfter=10)

    doc = SimpleDocTemplate(output_path, pagesize=letter)
    story = []

    protein_domains = []
    is_protein_domains_section = False
    has_clinvar_data = False
    clinvar_checked = False

    for line in text.splitlines():
        if line.startswith("Variant Analysis Report:"):
            story.append(Paragraph(line, header_style))
            story.append(Spacer(1, 12))
        elif line.startswith("Report generated on"):
            story.append(Paragraph(line, normal_style))
            story.append(Spacer(1, 12))
        elif any(line.startswith(prefix) for prefix in [
            "Cytogenetic band:", "High protein expression:", "Transcript length:", 
            "Translation length:", "Total number of exons:", "Number of coding exons:", 
            "Variant location:", "Variant classification:", "Variant condition:", 
            "Variant more info:"
        ]):
            story.append(split_and_style(line, normal_style))
            story.append(Spacer(1, 12))
            if line.startswith("Variant classification:") or line.startswith("Variant condition:") or line.startswith("Variant more info:"):
                has_clinvar_data = True
        elif line.startswith("Protein Domain(s):"):
            is_protein_domains_section = True
        elif is_protein_domains_section and line.startswith("Source:"):
            domain_parts = line.split(',')
            domain_data = {}
            for part in domain_parts:
                if ':' in part:
                    key, value = part.split(':', 1)
                    domain_data[key.strip()] = value.strip()
            protein_domains.append(domain_data)
        else:
            if is_protein_domains_section:
                if protein_domains and not clinvar_checked:
                    if not has_clinvar_data:
                        story.append(Paragraph("ClinVar:", bold_style))
                        story.append(Paragraph("No ClinVar submissions found for this rsID.", normal_style))
                        story.append(Spacer(1, 12))
                        clinvar_checked = True  # Prevent further messages
                    story.extend(create_protein_domains_table(protein_domains))
                    story.append(Spacer(1, 12))
                is_protein_domains_section = False
            story.append(Paragraph(line, normal_style))
            story.append(Spacer(1, 12))

    if is_protein_domains_section and protein_domains and not clinvar_checked:
        if not has_clinvar_data:
            story.append(Paragraph("ClinVar:", bold_style))
            story.append(Paragraph("No ClinVar submissions found for this rsID.", normal_style))
            story.append(Spacer(1, 12))
        story.extend(create_protein_domains_table(protein_domains))
        story.append(Spacer(1, 12))

    try:
        doc.build(story)
    except PermissionError as e:
        print(f"Error: {e}")
        print(f"Permission denied. The file '{output_path}' might be open in another application. Please close the file and try again.")


      
def truncate_hgvs_cdna_transcript_id(hgvs_cdna_transcript_id):
    return hgvs_cdna_transcript_id.split(':')[0].split('.')[0]

def get_cytogenetic_band(gene_symbol):
    search_url = f'https://api.genome.ucsc.edu/search?search={gene_symbol}&genome=hg38'
    search_response = requests.get(search_url)
    search_data = search_response.json()

    try:
        for match in search_data['positionMatches'][0]['matches']:
            if gene_symbol in match['posName'] and 'ENST' in match['hgFindMatches']:
                position = match['position']
                chrom, pos_range = position.split(':')
                start, end = pos_range.split('-')

                track_url = f'https://api.genome.ucsc.edu/getData/track?track=cytoBand;genome=hg38;chrom={chrom};start={start};end={end}'
                track_response = requests.get(track_url)
                track_data = track_response.json()

                cytogenetic_band = track_data.get('cytoBand', 'Band not found')
                chromosome = cytogenetic_band[0]['chrom'][3:]
                cytoband = cytogenetic_band[0]['name']
                cytogenetic_band = chromosome + cytoband
                print(f"Cytogenetic band: {cytogenetic_band}")
                break

    except (IndexError, KeyError) as e:
        print(f"Error handling API response: {e}")
        return "Gene symbol not found or data incomplete."

def get_ensembl_gene_id(gene_symbol):
    url = f"https://rest.ensembl.org/lookup/symbol/homo_sapiens/{gene_symbol}"
    headers = {"Content-Type": "application/json"}
    response = send_request(url, headers)
    if response:
        return response.json().get("id")
    return None

def get_high_protein_expression(ensembl_gene_id):
    url = f"https://www.proteinatlas.org/{ensembl_gene_id}.xml"
    response = send_request(url)
    high_protein_expression = []
    if response:
        root = ET.fromstring(response.content)
        for data in root.findall(".//data"):
            tissue = data.find('tissue')
            levels = data.findall('level[@type="expression"]')
            if tissue is not None and any(level.text.strip().lower() == "high" for level in levels):
                high_protein_expression.append(tissue.text)
        if high_protein_expression:
            print(f"High protein expression: {', '.join(high_protein_expression).lower()}")
        else:
            print("Protein not highly expressed.")

def get_ensembl_transcript_id(hgvs_cdna_transcript_id_truncated):
    url = f"https://rest.ensembl.org/xrefs/symbol/homo_sapiens/{hgvs_cdna_transcript_id_truncated}?external_db=RefSeq_mRNA"
    headers = {"Content-Type": "application/json"}
    response = send_request(url, headers)
    if response:
        data = response.json()
        for entry in data:
            if entry['type'] == 'transcript':
                return entry['id']
    return None

def get_current_version_hgvs_cdna_transcript_id(hgvs_cdna_transcript_id):
    hgvs_cdna_transcript_id_truncated = truncate_hgvs_cdna_transcript_id(hgvs_cdna_transcript_id)
    base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
    fetch_url = f"{base_url}efetch.fcgi?db=nucleotide&id={hgvs_cdna_transcript_id_truncated}&rettype=gb&retmode=xml"
    response = requests.get(fetch_url)
    if response.status_code == 200:
        root = ET.fromstring(response.content)
        for item in root.findall('.//GBSeq'):
            return item.find('GBSeq_accession-version').text
    else:
        print("Failed to retrieve current version data from NCBI.")
    return None

def get_grch38_variant_position(hgvs_cdna_transcript_id):
    def fetch_position(hgvs_cdna_transcript_id):
        encoded_identifier = quote(hgvs_cdna_transcript_id)
        url = f"https://www.ncbi.nlm.nih.gov/snp/?term={encoded_identifier}"
        response = send_request(url)
        
        if response:
            soup = BeautifulSoup(response.text, 'html.parser')
            dt_tags = soup.find_all('dt')
            for dt in dt_tags:
                if dt.text.strip() == "Chromosome:":
                    dd_tag = dt.find_next('dd')
                    entries = dd_tag.decode_contents().split('<br/>')
                    for entry in entries:
                        if "GRCh38" in entry:
                            entry_clean = BeautifulSoup(entry, 'html.parser').text.strip()
                            parts = entry_clean.split(' ')
                            for part in parts:
                                if "GRCh38" in part:
                                    position = part.split(':')[-1].replace('GRCh38', '').strip()
                                    return ''.join(filter(str.isdigit, position))
        return None

    position = fetch_position(hgvs_cdna_transcript_id)
    if position:
        return position

    current_version = get_current_version_hgvs_cdna_transcript_id(hgvs_cdna_transcript_id.split(':')[0])
    if current_version:
        hgvs_cdna_transcript_id_updated = f"{current_version}:{hgvs_cdna_transcript_id.split(':')[1]}"
        position = fetch_position(hgvs_cdna_transcript_id_updated)
        if position:
            return position

    return "GRCh38 chromosome information not found"

def get_transcript_details_and_ensembl_protein_id(ensembl_transcript_id, variant_position):
    url = f"https://rest.ensembl.org/lookup/id/{ensembl_transcript_id}?expand=1"
    headers = {"Content-Type": "application/json"}
    response = send_request(url, headers)
    if response:
        data = response.json()
        transcript_length = data.get('length', 'Transcript Length not available')
        translation = data.get('Translation', {})
        translation_length = translation.get('length', 'Translation length not available')
        total_exons = len(data['Exon']) if 'Exon' in data else 0
        coding_exons = sum(1 for exon in data['Exon'] if exon['start'] <= translation.get('end', 0) and exon['end'] >= translation.get('start', float('inf')))
        exon_number = next((index for index, exon in enumerate(data.get('Exon', []), start=1) if exon['start'] <= variant_position <= exon['end']), None)
        ensembl_protein_id = data['Translation']['id']
        print(f"Transcript length: {transcript_length}")
        print(f"Translation length: {translation_length}")
        print(f"Total number of exons: {total_exons}")
        print(f"Number of coding exons: {coding_exons}")
        print(f"Variant location: exon {exon_number} of {coding_exons}")
        return ensembl_protein_id
    else:
        print("Failed to retrieve transcript details.")

def get_protein_domains(ensembl_protein_id):
    url = f"https://rest.ensembl.org/overlap/translation/{ensembl_protein_id}"
    headers = {"Content-Type": "application/json"}
    response = send_request(url, headers)
    if response:
        domains = response.json()
        print("Protein Domain(s):")
        for domain in domains:
            if domain.get('type') in ['Pfam', 'Smart']:
                print(f"Source: {domain['type']}, Description: {domain.get('description', 'No description available')}, Start: {domain['start']}, End: {domain['end']}")
    else:
        print("Failed to retrieve protein domains.")

def get_rsID(hgvs_cdna_transcript_id):
    def fetch_rsid(hgvs_cdna_transcript_id):
        url = "https://www.ncbi.nlm.nih.gov/snp/"
        params = {'term': hgvs_cdna_transcript_id}
        response = send_request(url, params=params)
        if response:
            soup = BeautifulSoup(response.text, 'html.parser')
            rsid_link = soup.find('a', href=lambda href: href and '/snp/rs' in href)
            if rsid_link:
                return rsid_link.text.strip()
        return None

    rsID = fetch_rsid(hgvs_cdna_transcript_id)
    if rsID:
        return rsID

    current_version = get_current_version_hgvs_cdna_transcript_id(hgvs_cdna_transcript_id.split(':')[0])
    if current_version:
        hgvs_cdna_transcript_id_updated = f"{current_version}:{hgvs_cdna_transcript_id.split(':')[1]}"
        rsID = fetch_rsid(hgvs_cdna_transcript_id_updated)
        if rsID:
            return rsID

    return "rsID not found"

def get_clinvar_data(rsID):
    url = f"https://www.ncbi.nlm.nih.gov/clinvar/?term={rsID}"
    response = send_request(url)
    extracted_data = []
    if response:
        soup = BeautifulSoup(response.text, 'html.parser')
        tables = soup.find_all('table')
        
        if len(tables) > 4:
            correct_table = tables[4]
            rows = correct_table.find_all('tr')
            
            for row in rows:
                cells = row.find_all('td')
                if len(cells) >= 5:
                    classification_info = cells[0].text.strip()
                    condition_info = cells[2].text.strip()
                    more_info = cells[4].text.strip()
                    if "(more)" in more_info:
                        more_info_parts = more_info.split("(more)")
                        if len(more_info_parts) > 1:
                            more_info = more_info_parts[1].strip()
                    if "(less)" in more_info:
                        more_info = more_info.replace("(less)", "").strip()
                    extracted_data.append({
                        'Variant classification': classification_info,
                        'Variant condition': condition_info,
                        'Variant more info': more_info
                    })

            if extracted_data:
                for data in extracted_data:
                    for key, value in data.items():
                        value = ' '.join(value.split())
                        print(f"{key}: {value}")
                return True  
            else:
                return False  
        else:
            return False  
    else:
        print("Failed to retrieve data from ClinVar.")
        return False  

@capture_output
def program(gene_symbol=gene_symbol, hgvs_cdna_transcript_id=hgvs_cdna_transcript_id):
    print_header(gene_symbol)
    get_cytogenetic_band(gene_symbol)
    ensembl_gene_id = get_ensembl_gene_id(gene_symbol)
    get_high_protein_expression(ensembl_gene_id)
    hgvs_cdna_transcript_id_truncated = truncate_hgvs_cdna_transcript_id(hgvs_cdna_transcript_id)
    ensembl_transcript_id = get_ensembl_transcript_id(hgvs_cdna_transcript_id_truncated)
    variant_position = int(get_grch38_variant_position(hgvs_cdna_transcript_id))
    ensembl_protein_id = get_transcript_details_and_ensembl_protein_id(ensembl_transcript_id, variant_position)
    get_protein_domains(ensembl_protein_id)
    rsID = get_rsID(hgvs_cdna_transcript_id)
    get_clinvar_data(rsID)

captured_text = program()
create_pdf_from_text(captured_text, output_pdf_file_path)
